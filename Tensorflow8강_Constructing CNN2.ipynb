{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tensorflow8강 Constructing CNN2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fully connected layer**\n",
    "![ex8_1](./image/8_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**loss**\n",
    "![ex8_2](./image/8_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdamOptimizer**  \n",
    "mini-batch로 gradient decent를 시키면 minimum과 가까워지긴 하지만 진동을 발생한다.\n",
    "관성과 비슷하게 momentum을 주게되면(수치해석적으로 무게를 주게되면) 방향을 쉽게 바꾸지 못한다.\n",
    "![ex8_3](./image/8_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**drop out**  \n",
    "overfitting을 막아주고 balancing을 잡아주고, 연산량도 줄여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image  # image 출력을 위한 library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.getcwd() + \"/test_image/jooseok_gray.png\"\n",
    "label_dir = os.getcwd() + \"/test_image/label.csv\"\n",
    "\n",
    "image_list = [image_dir]\n",
    "label_list = [label_dir]\n",
    "\n",
    "image_queue = tf.train.string_input_producer(image_list)\n",
    "label_queue = tf.train.string_input_producer(label_list)\n",
    "\n",
    "image_reader = tf.WholeFileReader()\n",
    "label_reader = tf.TextLineReader()\n",
    "\n",
    "image_key, image_value = image_reader.read(image_queue)\n",
    "label_key, label_value = label_reader.read(label_queue)\n",
    "\n",
    "image = tf.image.decode_png(image_value)\n",
    "label = tf.decode_csv(label_value, record_defaults=[[0]])\n",
    "\n",
    "x = tf.cast(image, tf.float32)\n",
    "y_ = tf.cast(label, tf.float32)\n",
    "\n",
    "y_ = tf.reshape(y_, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH =50\n",
    "IMAGE_HEIGHT = 50\n",
    "#HIDDEN1_SIZE = 32\n",
    "#HIDDEN2_SIZE = 64\n",
    "#CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1_w = tf.Variable(tf.truncated_normal([5, 5, 1, 32]))  # width, height, depth, batch\n",
    "hidden1_b = tf.Variable(tf.zeros([32]))\n",
    "\n",
    "hidden2_w = tf.Variable(tf.truncated_normal([5, 5, 32, 64]))\n",
    "hidden2_b = tf.Variable(tf.zeros([64]))\n",
    "\n",
    "\n",
    "fc_w = tf.Variable(tf.truncated_normal([IMAGE_WIDTH * IMAGE_HEIGHT * 64, 10]))  # CLASS는 임의의 숫자 \n",
    "fc_b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "out_w = tf.Variable(tf.truncated_normal([10, 1]))\n",
    "out_b = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution\n",
    "x_image = tf.reshape(x, [-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1])  # reshape를 해주어야 dimension오류가 없다.\n",
    "\n",
    "h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, hidden1_w, strides=[1, 1, 1, 1], padding=\"SAME\") + hidden1_b)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, hidden2_w, strides=[1, 1, 1, 1], padding=\"SAME\") + hidden2_b)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully connected layer\n",
    "h_flat = tf.reshape(h_pool2, [-1, IMAGE_WIDTH * IMAGE_HEIGHT * 64])\n",
    "h_fc1 = tf.nn.softmax(tf.matmul(h_flat, fc_w) + fc_b)\n",
    "\n",
    "drop_fc = tf.nn.dropout(h_fc1, 0.7)\n",
    "pred = tf.matmul(drop_fc, out_w) + out_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y_))\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y_, 1))  # 1: reduce할 때, 어느 방향으로 할꺼\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "loss:  21.918861\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  0.69004714\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  0.68849725\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  21.907354\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  21.903517\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  21.899994\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  21.896397\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  0.6807501\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  21.889061\n",
      "accuracy:  1.0\n",
      "=========================\n",
      "loss:  0.677652\n",
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    " with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(10):\n",
    "        sess.run(train)\n",
    "        _loss, _accuracy = sess.run([loss, accuracy])\n",
    "        print(\"=========================\")\n",
    "        print(\"loss: \", _loss)\n",
    "        print(\"accuracy: \", _accuracy)\n",
    "    \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python3",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
